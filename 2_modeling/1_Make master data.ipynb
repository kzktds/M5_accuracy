{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from multiprocessing import Pool\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各種パラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 207                        # Or model version\n",
    "SEED = 1224                      # We want all things\n",
    "seed_everything(SEED)            # to be as deterministic \n",
    "\n",
    "TARGET      = 'sales'            # Our target\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1913+28            # End day of our train set\n",
    "P_HORIZON   = 28                 # Prediction horizon\n",
    "\n",
    "# 読み込みが必要なpklファイルのパス\n",
    "BASE     = './grid_part_1_update.pkl'\n",
    "PRICE    = './grid_part_2_update.pkl'\n",
    "CALENDAR = './grid_part_3_update.pkl'\n",
    "MEAN_ENC = './mean_encoding_df_update_nonleak.pkl'\n",
    "\n",
    "# 読み込みが必要なcsvファイルのパス\n",
    "EVALUATION   = './sales_train_evaluation.csv'\n",
    "CALENDAR_CSV = '../data/calendar.csv'\n",
    "PRICE_CSV    = '../data/sell_prices.csv'\n",
    "SAMPLE_CSV   = '../data/sample_submission.csv'\n",
    "\n",
    "# CVを行う区切りのリスト\n",
    "SPLIT_LIST = [[1886, 1913]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'poisson',\n",
    "                'tweedie_variance_power': 1.1,\n",
    "                'metric': 'rmse',\n",
    "                'subsample': 0.5,\n",
    "                'subsample_freq': 1,\n",
    "                'learning_rate': 0.03,\n",
    "                'num_leaves': 2**11-1,\n",
    "                'min_data_in_leaf': 2**12-1,\n",
    "                'feature_fraction': 0.5,\n",
    "                'max_bin': 100,\n",
    "                'n_estimators': 3000,\n",
    "                'boost_from_average': False,\n",
    "                'verbose': -1,\n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"categorical_feat = [\n",
    "    \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\", \n",
    "    \"tm_wm\", \"tm_dw\", \"tm_w_end\", \"tm_y\",\n",
    "]\"\"\"\n",
    "\n",
    "categorical_feat = [\n",
    "    \"event_name_1\", \"tm_wm\", \"tm_dw\", \"tm_w_end\", \"tm_y\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(original_df, feat_path, feat_names=None, merge_key=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    パスとキーを指定して、特徴量を追加する   \n",
    "    - original_df : 特徴を追加するDataFrame\n",
    "    - feat_path   : 追加する特徴(pkl)のパス\n",
    "    - feat_names  : pklの中で、結合する特徴を絞り込みたい場合に指定する\n",
    "    - merge_key   : pklをmergeで結合する場合、キーを指定する(Noneの場合concatする)\n",
    "    \n",
    "    \"\"\"\n",
    "    tmp = pd.read_pickle(feat_path)\n",
    "    \n",
    "    if feat_names is not None: \n",
    "        tmp = tmp[feat_names]\n",
    "        \n",
    "    if merge_key is None:\n",
    "        tmp = tmp[tmp.index.isin(original_df.index)]\n",
    "        original_df = pd.concat([original_df, tmp], axis=1)\n",
    "    else:\n",
    "        original_df = pd.merge(original_df, tmp, on=merge_key, how=\"left\")\n",
    "    \n",
    "    return original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_store(store):\n",
    "    \"\"\"\n",
    "    store_idを指定して、学習用のデータフレームを取得する\n",
    "    \"\"\"  \n",
    "    # 3つのpklを結合してベースとなるデータフレームを作成\n",
    "    df = pd.concat([pd.read_pickle(BASE),\n",
    "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
    "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "    \n",
    "    # store_id(店のID)で絞り込み\n",
    "    df = df[df['store_id']==store]\n",
    "    \n",
    "    # 平均エンコーディング(MEAN_ENC)用の特徴リスト\n",
    "    mean_features = ['enc_timeseries_state_id_mean',\n",
    "                   'enc_timeseries_state_id_std',\n",
    "                   'enc_timeseries_store_id_mean',\n",
    "                   'enc_timeseries_store_id_std',\n",
    "                   'enc_timeseries_cat_id_mean',\n",
    "                   'enc_timeseries_cat_id_std', \n",
    "                   'enc_timeseries_dept_id_mean',\n",
    "                   'enc_timeseries_dept_id_std', \n",
    "                   'enc_timeseries_state_id_cat_id_mean',\n",
    "                   'enc_timeseries_state_id_cat_id_std',\n",
    "                   'enc_timeseries_state_id_dept_id_mean',\n",
    "                   'enc_timeseries_state_id_dept_id_std',\n",
    "                   'enc_timeseries_store_id_cat_id_mean',\n",
    "                   'enc_timeseries_store_id_cat_id_std',\n",
    "                   'enc_timeseries_store_id_dept_id_mean',\n",
    "                   'enc_timeseries_store_id_dept_id_std', \n",
    "                   'enc_timeseries_item_id_mean',\n",
    "                   'enc_timeseries_item_id_std', \n",
    "                   'enc_timeseries_item_id_state_id_mean',\n",
    "                   'enc_timeseries_item_id_state_id_std',\n",
    "                   'enc_timeseries_item_id_store_id_mean',\n",
    "                   'enc_timeseries_item_id_store_id_std']\n",
    "    \n",
    "    # 前後の祝日に関する情報のリスト\n",
    "    holiday_features = [\n",
    "        'id', 'd','days_to_next_holiday','days_from_prev_holiday', 'monday_or_friday'\n",
    "    ]\n",
    "    \n",
    "    # 各種特徴追加(追加する場合はここに羅列する)\n",
    "    CROSTON_TSB = \"../20200602_追加データの確認/Croston_TSB_update_plus28.pkl\"\n",
    "    CROSTON     = \"../20200602_追加データの確認/Croston_update_plus28.pkl\"\n",
    "    WEEK_WM_AVE = \"../20200602_追加データの確認/week_w_moving_average.pkl\"\n",
    "    W_M_AVE     = \"../20200602_追加データの確認/weighted_average_update.pkl\"\n",
    "    HOLIDAY     = \"../20200602_追加データの確認/holiday_workingday_holidayLength.pkl\"\n",
    "    PRI_STATE   = \"../20200602_追加データの確認/sell_price_state.pkl\"\n",
    "    HOLIDAY2    = \"../20200602_追加データの確認/holiday_features.pkl\"\n",
    "    \n",
    "    df = merge_df(df, feat_path=MEAN_ENC, feat_names=mean_features, merge_key=None)                         # 平均エンコードした特徴\n",
    "    df = merge_df(df, feat_path=CROSTON_TSB, feat_names=[\"id\", \"d\", \"Forecast\"], merge_key=[\"id\", \"d\"])     # CrostonTSB\n",
    "    df = merge_df(df, feat_path=CROSTON, feat_names=[\"id\", \"d\", \"Forecast\"], merge_key=[\"id\", \"d\"])         # Croston\n",
    "    df = merge_df(df, feat_path=WEEK_WM_AVE, feat_names=None, merge_key=[\"id\", \"tm_y\", \"tm_w\"])             # 週の指数平滑化移動平均\n",
    "    df = merge_df(df, feat_path=W_M_AVE, feat_names=None, merge_key=None)                                  # salesの指数平滑化移動平均\n",
    "    df = merge_df(df, feat_path=HOLIDAY, feat_names=None, merge_key=[\"d\", \"state_id\"])                      # 休日関連\n",
    "    df = merge_df(df, feat_path=PRI_STATE, feat_names=None, merge_key=[\"id\", \"d\"])                          # 値段の下一桁\n",
    "    df = merge_df(df, feat_path=HOLIDAY2, feat_names=holiday_features, merge_key=[\"id\", \"d\"])                # 前後の祝日\n",
    "    \n",
    "    features = df.columns\n",
    "    \n",
    "    return df, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORES_IDS = pd.read_csv(EVALUATION)['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA_1\n"
     ]
    }
   ],
   "source": [
    "for store_id in STORES_IDS:\n",
    "    print(store_id)\n",
    "    grid_df, _ = get_data_by_store(store_id)\n",
    "    grid_df.to_pickle(f\"./grid_df_master_{store_id}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
